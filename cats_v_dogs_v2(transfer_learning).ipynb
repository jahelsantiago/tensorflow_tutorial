{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats-v-dogs_v2(transfer learning).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA+gbJvHSmPD23FWRdk+y3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahelsantiago/tensorflow_tutorial/blob/master/cats_v_dogs_v2(transfer_learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDMU2u0lzVNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWsjF7Plzo71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "193ba5ac-29e1-428e-f960-9ce7c153efa6"
      },
      "source": [
        "#descargamos el model  inception\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-10 00:39:40--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 74.125.203.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  29.5MB/s    in 2.8s    \n",
            "\n",
            "2020-08-10 00:39:43 (29.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZWr4yQCbxq",
        "colab_type": "text"
      },
      "source": [
        "cargamos el modelo de inception y elegimos la ultima layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW81KQwxzrD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = \"/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\" # el path de donde estan ubicados los weights\n",
        "\n",
        "pretrain_model = InceptionV3(input_shape=(150,150,3), #input de las imagenes\n",
        "                             include_top = False, #elige si incluir la ultima neurona (output layer)\n",
        "                             weights = None) #no incluir los weights del modelo\n",
        "\n",
        "pretrain_model.load_weights(weights_path) #asignamos los pesos al modelo\n",
        "\n",
        "for layer in pretrain_model.layers:\n",
        "  layer.trainable = False #elegimos las neuronas como no entrenable\n",
        "\n",
        "#pretrain_model.summary()\n",
        "\n",
        "last_layer = pretrain_model.get_layer(\"mixed7\") #elegimos la que queremos que sea la ultima neurona\n",
        "last_layer_output = last_layer.output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNk5vDBG02Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_layer_output) #asignamos como neurona consecuente a la ultima del inception, una flatten\n",
        "x = layers.Dense(1024, activation='relu')(x) \n",
        "x = layers.Dropout(0.2)(x) #asignamos dropout a la anterior\n",
        "x = layers.Dense  (1, activation='sigmoid')(x) #asignamos la ultima ultima\n",
        "\n",
        "model = Model( pretrain_model.input, x) #creamos el modelo dandole un imput y una output\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPvAxjNK3nGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "13914061-31a3-462a-9f08-2fcdea43631b"
      },
      "source": [
        "!wget --no-check-certificate \\ #descargamos los datos del\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-10 00:59:11--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 64.233.189.128, 108.177.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  21.6MB/s    in 3.0s    \n",
            "\n",
            "2020-08-10 00:59:15 (21.6 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TSToe654OE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os \n",
        "import zipfile \n",
        "\n",
        "zip = zipfile.ZipFile(\"/tmp/cats_and_dogs_filtered.zip\", \"r\")\n",
        "zip.extractall(\"/tmp\")\n",
        "zip.close()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX4Vdld-4iIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e531256a-aefd-421d-f7dc-76419e38116e"
      },
      "source": [
        "train_datagen = ImageDataGenerator( #creamos el data augmented para el train\n",
        "    rescale = 1./255.,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1./255. ) #creamos el data augmented para el test\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( #leemos los datos y los label each one\n",
        "    \"/tmp/cats_and_dogs_filtered/train\",\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary', \n",
        "    target_size = (150, 150)     \n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( \n",
        "    \"/tmp/cats_and_dogs_filtered/validation\",\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary', \n",
        "    target_size = (150, 150)    \n",
        ")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY2_f_yK6Swr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zv_HPQtCVYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}